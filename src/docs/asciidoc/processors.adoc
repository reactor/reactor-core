Processors are a special kind of `Publisher` that are also a `Subscriber`. That means
that you can `subscribe` to a `Processor`, but you can also call methods to manually inject
data into the sequence or terminate it.

Reactor offers a basic interface for Processors that have the same input and output types,
the `BalancedFluxProcessor`, with different flavors exposed on the `Processors` utility
class.

Each flavor has a few particular semantics, but before you start looking into these, you
need to ask yourself the following question:

= Do I Need a Processor?
Most of the time, you should try to avoid using a `Processor`. They are harder to use
correctly and prone to some corner cases.

If you think a `Processor` could be a good match for your use case, ask yourself if you
have tried these two alternatives:

. Could an operator or combination of operators fit the bill? (See <<which-operator>>)
. Could a <<producing,"generator">> operator work instead? (Generally, these operators
are made to bridge APIs that are not reactive, providing a "sink" that is similar in
concept to a `Processor` in the sense that it lets you populate the sequence with data or
terminate it).

If, after exploring the above alternatives, you still think you need a `Processor`, read
the <<processor-overview>> section below to learn about the different implementations.

= Safely Produce from Multiple Threads by Using the `FluxSink` Facade
Rather than directly using Reactor `Processors`, it is a good practice to obtain a `FluxSink`
for the `Processor` by calling `sink()` **once** (and storing the result in a variable to
reuse it).

`BalancedFluxProcessor` sinks safely gate multi-threaded producers and can be used by
applications that generate data from multiple threads concurrently. For example, a
thread-safe serialized sink can be created for the `unicast` flavor:

[source,java]
----
BalancedFluxProcessor<Integer> processor = Processors.unicast().build();
FluxSink<Integer> sink = processor.sink(overflowStrategy);
----

Multiple producer threads may concurrently generate data on the following serialized
sink:

[source,java]
----
sink.next(n);
----

Overflow from `next` behaves in two possible ways, depending on the `Processor` and its
configuration:

* An unbounded processor handles the overflow itself by dropping or buffering.
* A bounded processor blocks or "spins" on the `IGNORE` strategy or applies the
`overflowStrategy` behavior specified when creating the `sink`.


[[processor-overview]]
= Overview of Available Processors
Reactor Core comes with several flavors of `Processor`. Not all processors have the same
semantics but are roughly split into four categories, described below:

* *simple* (`direct` and `unicast` flavors): These processors have more limitations than the others.
`direct` doesn't manage backpressure, while `unicast` is limited to a single `Subscriber`.
Pushing data through direct user action (calling their `FluxSink`'s methods directly) is
the favored way of using these.
* *synchronous* (`emitter` and `replay` flavors): These processors are meant to push data
both through user action and by subscribing to an upstream `Publisher` and synchronously
draining it.
* *asynchronous* (`fanOut` flavor): These processors can push data obtained from
**multiple** upstream `Publishers`. They are more robust but also are a bit more costly
to instantiate, establishing more resources in order to deal with their multiple upstreams.
* *mono* (`first` flavor): These processors, when attached to a `Publisher` source, only
propagate at most one element from the source. Their `sink()` is actually a `MonoSink<T>`,
which limits the sink interactions to follow the semantics of `Mono` (0-1 elements).



== Direct Processor
[source,java]
----
BalancedFluxProcessor<Integer> direct = Processors.direct();
----

A **direct** `Processor` can dispatch signals to zero to many `Subscribers`, but has the
limitation of not handling backpressure.

As a consequence, a direct `Processor` signals an `IllegalStateException` to its
subscribers if you push N elements through it but at least one of its subscribers has
requested less than N.

Once the `Processor` has terminated (usually through its `FluxSink` `error(Throwable)`
or `complete()` methods being called), it lets more subscribers subscribe but
replays the termination signal to them immediately.

== Unicast Processor
[source,java]
----
UnicastProcessorBuilder<Integer> builder = Processors.unicast();
BalancedFluxProcessor<Integer> unicast = builder.build();
----

A **unicast** `Processor` can deal with backpressure using an internal buffer.
The trade-off is that it can have *at most one* `Subscriber`.

Such a `Processor` has a few more options in its builder. For instance, by default it is
_unbounded_: if you push any amount of data through it while its `Subscriber` has not yet
requested data, it will buffer all of the data.

This can be changed by providing a custom `Queue` implementation for the internal
buffering through the `queue(Queue)` builder method. If that queue is bounded, the processor
could reject the push of a value when the buffer is full and not enough requests from
downstream have been received.

In that _bounded_ case, the processor can also be built with a callback that is invoked
on each rejected element, allowing for cleanup of these rejected elements.

== Emitter Processor
[source,java]
----
EmitterProcessorBuilder<Integer> builder = Processors.emitter();
BalancedFluxProcessor<Integer> emitter = builder.build();
----

An **emitter** `Processor` is capable of emitting to several subscribers, while honoring
backpressure for each of its subscribers. It can also subscribe to a `Publisher` and
relay its signals synchronously.

Initially, when it has no subscriber, it can still accept a few data pushes up to a
configurable `bufferSize`. After that point, if no `Subscriber` has come in and consumed
the data, calls to `onNext` block until the processor is drained (which can only happen
concurrently by then).

Thus, the first `Subscriber` to subscribe receives up to `bufferSize` elements upon
subscribing. However, after that, the processor stops replaying signals to additional
subscribers. These subsequent subscribers instead only receive the signals pushed through
the processor *after* they have subscribed. The internal buffer is still used for
backpressure purposes.

By default, if all of its subscribers are cancelled (which basically means they have all
un-subscribed), it will clear its internal buffer and stop accepting new subscribers.
This can be deactivated by using the `noAutoCancel()` method in the builder.

== Replay Processor
[source,java]
----
ReplayProcessorBuilder<Integer> builder = Processors.replay();
BalancedFluxProcessor<Integer> replay = builder.build();
----

A **replay** `Processor` caches elements that are either pushed directly through its `FluxSink`
or elements from an upstream `Publisher` and replays them to late subscribers.

Depending on the methods called on the builder, it can create a replay Processor in
multiple configurations:

* Caching an unbounded history (no builder configuration and direct call to `build()`, or
call to `historySize(int, true)`).
* Caching a bounded history (`historySize(int)`).
* Caching time-based replay windows, by only specifying a TTL (`maxAge(Duration)`).
* Caching combination of history size and time window, by specifying both TTL
(`maxAge(Duration)`) and history size (`historySize(int)`).

There is also a factory method to produce a replay processor that caches the last pushed
element: `Processors.cacheLast()`.

== FanOut Processor
[source,java]
----
FanOutProcessorBuilder<Integer> builder = Processors.fanOut();
BalancedFluxProcessor<Integer> fanOut = builder.build();
----

A **fan out** `Processor` is an **asynchronous** processor capable of relaying elements from
multiple upstream `Publishers` when created in the `shared` configuration (see the
`share(boolean)` option of the builder).

Note that the share option is mandatory if you intend to concurrently call the Processor's
`onNext`, `onComplete`, or `onError` methods directly or from a concurrent upstream `Publisher`.

Otherwise, such concurrent calls are illegal, as the processor is then fully compliant
with the Reactive Streams specification.

A fan out processor is capable of fanning out to multiple `Subscribers`,
with the added overhead of establishing resources to keep track of each `Subscriber`
until an `onError(Throwable)` or `onComplete()` signal is pushed through the processor or
until the associated `Subscriber` is cancelled.

This variant uses a `Thread`-per-`Subscriber` model.

The maximum number of downstream subscribers is driven by the `executor(ExecutorService)`
builder option. Provide a bounded `ExecutorService` to limit it to a specific number.

The processor is backed by a `RingBuffer` data structure that stores pushed signals. Each
`Subscriber` thread keeps track of its associated demand and the correct indexes in the
`RingBuffer`.

This processor also has an `autoCancel` builder option: If set to `true` (the default),
it results in the source `Publisher`(s) being cancelled when all subscribers are
cancelled.

== First Processor
[source,java]
----
MonoFirstProcessorBuilder<Integer> builder = Processors.first();
BalancedMonoProcessor<Integer> first = builder
    .attachSource(Flux.range(1, 10))
    .build();
//will emit `1`
----

A **first** `Processor` is a `BalancedMonoProcessor` that captures the _first_ element
that is pushed through it (either manually or by an upstream source `Publisher`) and
replays it to further `Subscribers`.