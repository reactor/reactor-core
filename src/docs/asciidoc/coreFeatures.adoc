[[core-features]]
== Reactor Core Features
`reactor-core` is the main artifact of the project, a reactive library that
focuses on the Reactive Streams specification and targets Java 8.

Reactor introduces composable reactive types that implement `Publisher` but also
provide a rich vocabulary of operators, `Flux` and `Mono`. The former represents
a reactive sequence of 0..N items, while the later represents a single-valued-or-empty
result.

This distinction allows to carry a bit of semantic into the type, indicating the
rough cardinality of the asynchronous processing. For instance, an HTTP request
only produces one response so there wouldn't be much sense in doing a `count`
operation... Expressing the result of such an HTTP call as a
`Mono<HttpResponse>` thus makes more sense than as a `Flux<HttpResponse>`, as it
offers only operators that are relevant to a "zero or one item" context.

In parallel, operators that change the maximum cardinality of the processing
will also switch to the relevant type. For instance the `count` operator exists
in `Flux`, but returns a `Mono<Long>`.

[[flux]]
=== `Flux`, an asynchronous sequence of 0-n items

image::https://raw.githubusercontent.com/reactor/projectreactor.io/master/src/main/static/assets/img/marble/flux.png[Flux]


A `Flux<T>` is a standard `Publisher<T>` representing an asynchronous sequence
of 0 to N emitted items, optionally terminated by either a success signal or an
error.

As in the RS spec, these 3 types of signal translate to calls to downstream's
`onNext`, `onComplete` or `onError` methods.

With this large scope of possible signal, `Flux` is the general-purpose reactive
type. Note that all events, even terminating ones, are optional: no onNext event
but an onComplete event represents an _empty_ finite sequence, but remove the
onComplete and you have an _infinite_ empty sequence. Similarly, infinite
sequences are not necessarily empty: `Flux.interval(Duration)` produces a
`Flux<Long>` that is infinite and emits regular ticks from a clock.

[[mono]]
=== `Mono`, an asynchronous 0-1 result
image::https://raw.githubusercontent.com/reactor/projectreactor.io/master/src/main/static/assets/img/marble/mono.png[Mono]

A `Mono<T>` is a specialized `Publisher<T>` that emits at most one item then
optionally terminates with an `onComplete` signal or an `onError`.

As such it offers only a relevant subset of operators. For instance, combination
operators can either ignore the right hand-side emissions and return another
`Mono` or emit values from both sides, in which case they'll switch to a `Flux`.

Note that a `Mono` can be used to represent no-value asynchronous processes that
only have the concept of completion (think `Runnable`): just use an empty
`Mono<Void>`.

=== Simple ways to create a Flux/Mono and to subscribe to it
The easiest way to get started with `Flux` and `Mono` is to use one of the
numerous factory methods found in their respective classes.

For instance, to create a simple sequence of `String`, you can either enumerate
them or put them in a collection and create the Flux from it:

[source,java]
----
Flux<String> seq1 = Flux.just("foo", "bar", "foobar");

List<String> iterable = Arrays.asList("foo", "bar", "foobar");
Flux<String> seq2 = Flux.fromIterable(iterable);
----

Other examples of factory methods include:

[source,java]
----
Mono<String> noData = Mono.empty(); <1>

Mono<String> data = Mono.just("foo");

Flux<Integer> numbersFromFiveToSeven = Flux.range(5, 3); <2>
----
<1> notice the factory method honors the generic type even though there will be
no value
<2> the subtlety is that the first parameter is the start of the range, while
the second parameter is the number of items to produce.

When it comes to subscribing, `Flux` and `Mono` make use of Java 8 lambdas. You
have a wide choice of `.subscribe()` variants that take lambdas for different
combinations of callbacks:

[[subscribeMethods]]
.Lambda-based subscribe variants for `Flux`
[source,java]
----
subscribe(); <1>

subscribe(Consumer<? super T> consumer); <2>

subscribe(Consumer<? super T> consumer,
          Consumer<? super Throwable> errorConsumer); <3>

subscribe(Consumer<? super T> consumer,
			    Consumer<? super Throwable> errorConsumer,
          Runnable completeConsumer); <4>

subscribe(Consumer<? super T> consumer,
			    Consumer<? super Throwable> errorConsumer,
          Runnable completeConsumer,
          Consumer<? super Subscription> subscriptionConsumer); <5>
----
<1> Just subscribe and trigger the sequence.
<2> Do something with each produced value.
<3> Deal with values but also react to an error.
<4> Deal with values, errors but also execute some code when the sequence
successfully completes.
<5> Deal with values, errors, successful completion but also do something with
the `Subscription` produced by this `subscribe` call.

TIP: These variants return a reference to the subscription that one can use to
cancel said subscription when no more data is needed. Upon cancellation, the
source should stop producing values and clean up any resources it created. This
cancel and clean-up behavior is represented in Reactor by the general-purpose
`Disposable` interface.

These are convenience variant over the Reactive Streams defined subscribe:

[source,java]
----
subscribe(Subscriber<? super T> subscriber);
----

That last variant is useful if you already have a `Subscriber` handy, but more
often you'll need it because you want to do something subscription-related in
the other callbacks. Most probably, that'd be dealing with backpressure and
triggering the requests yourself.

In that case, you can ease things up by using the `BaseSubscriber` abstract
class, which offers convenience methods for that:

.Using a `BaseSubscriber` to fine tune backpressure
[source,java]
----
Flux<String> source = someStringSource();

source.map(String::toUpperCase)
      .subscribe(new BaseSubscriber<String>() { <1>
          @Override
          protected void hookOnSubscribe(Subscription subscription) {
            <2>
	          request(1); <3>
          }

          @Override
          protected void hookOnNext(String value) {
            request(1); <4>
          }

          <5>
      });
----
<1> The `BaseSubscriber` is an abstract class so we create an anonymous
implementation and specify the generic type.
<2> `BaseSubscriber` defines hooks for the various signal handling you can
implement in a `Subscriber`. It also deals with the boilerplate of capturing the
`Subscription` object so you can manipulate it in other hooks.
<3> `request(n)` is such a method: it propagates backpressure request to the
capture subscription from any of the hooks. Here we start the stream by
requesting 1 element from the source.
<4> upon receiving a new value, we continue requesting new items from the source
one by one.
<5> Other hooks are `hookOnComplete`, `hookOnError`, `hookOnCancel` and
`hookFinally` (which is always called when the sequence terminates, with the
type of termination passed in as a `SignalType` parameter).

WARNING: When manipulating request like that, you must be careful to produce
enough demand for the sequence to advance or your Flux will get "stuck". That is
the reason why `BaseSubscriber` forces you to implement the subscription and
onNext hooks, where you should usually call `request` at least once.

[[schedulers]]
=== `Schedulers`
Reactor, like RxJava, can be considered **concurrency agnostic**. It doesn't
enforce a concurrency model but rather leave you, the developer, in command.

But that doesn't prevent the library from helping you with concurrency...

In Reactor, the execution model and where the execution happens is determined by
the `Scheduler` that is used. A `Scheduler` is an interface that can abstract
a wide range of implementations. The `Schedulers` class has static methods that
give access to the following execution contexts:

- the current thread (`Schedulers.immediate()`)
- a single, reusable thread (`Schedulers.single()`). Note that this method
reuses the same thread for all callers, until the Scheduler is disposed. If you
want a per-call dedicated thread, use `Schedulers.newSingle()` instead.
- an elastic thread pool (`Schedulers.elastic()`). It will create new worker
pools as needed, and reuse idle ones unless they stay idle for too long (default
is 60s), in which case the workers are disposed. This is a good choice for I/O
blocking work for instance.
- a fixed pool of workers that is tuned for parallel work
(`Schedulers.parallel()`). It will create as many workers as you have CPU cores.
- a time-aware scheduler capable of scheduling tasks in the future, including
recurring tasks (`Schedulers.timer()`).

Additionally, you can create a `Scheduler` out of any pre-existing
`ExecutorService` footnote:[you can also create one from an `Executor`, although
it is discouraged] using `Schedulers.fromExecutorService(ExecutorService)`, and
also create new instances of the various scheduler types using `newXXX` methods.

NOTE: Operators are implemented using non-blocking algorithms that are
tuned to facilitate the work-stealing that can happen in some Schedulers.

Some operators use a specific Scheduler from `Schedulers` by default (and will
usually give you the option of providing a different one). For instance, calling
the factory method `Flux.intervalMillis(300)` will produces a `Flux<Long>` that
ticks every 300ms. This is enabled by `Schedulers.timer()` by default.

Reactor offers two means of switching execution context (or `Scheduler`) in a
reactive chain: `publishOn` and `subscribeOn`. Both take a `Scheduler` and allow
to switch the execution context to that scheduler. But `publishOn` placement in
the chain matters, while `subscribeOn`'s doesn't. To understand that difference,
you first have to remember that <<reactive.subscribe>>.

In Reactor, when you chain operators you wrap as many `Flux`/`Mono` specific
implementations inside one another. And as soon as you subscribe, a chain of
`Subscriber` is created backward. This is effectively hidden from you and all
you can see is the outer layer of `Flux` (or `Mono`) and `Subscription`, but
these intermediate operator-specific subscribers are where the real work happens.

With that knowledge, let's have a closer look at the two operators:

- `publishOn` applies as any other operator, in the middle of that subscriber
chain. As such, it takes signals from downstream and replays them upstream, but
executing the callback on a worker from the associated `Scheduler`. So it
**affects where the subsequent operators will execute** (until another publishOn
is chained in).
- `scheduleOn` rather applies to the subscription process, when that backward
chain is constructed. As a consequence, no matter where you place the
`subscribeOn` in the chain, **it is always the context of the source emission**
that is affected. However, this doesn't affect the behavior of subsequent calls
to `publishOn`: they will still switch the execution context for the part of the
chain after them. Also, only the earliest `subscribeOn` call in the chain is
actually taken into account.

=== Handling Errors
TIP: For a quick look at the available operators for error handling, see
<<which.errors,the relevant operator decision tree>>.

In Reactive Streams, errors are terminal events. As soon as an error occurs, it
stop the sequence and gets propagated down the chain of operators to the last
step, the `Subscriber` you defined and its `onError` method.

Such errors should still be dealt with at the application level, for instance
by displaying an error notification in a UI, or sending a meaningful error
payload in a REST endpoint, so the subscriber's `onError` method should always
be defined.

WARNING: If not defined, `onError` will throw an `UnsupportedOperationException`.
You can further detect and triage it by the `Exceptions.isErrorCallbackNotImplemented`
method.

But Reactor also offers alternative means of dealing with errors in the middle
of the chain, as error-handling operators.

IMPORTANT: Before you learn about error-handling operators, you must keep in
mind that *any error in a reactive sequence is a terminal event*. Even if an
error-handling operator is used, it doesn't allow the *original* sequence to
continue, but rather converts the `onError` signal into the start of a *new*
sequence (the fallback one). As such it replaces the terminated sequence
_upstream_.

Let's go through each mean of error handling one-by-one. When relevant we'll
make a parallel with imperative world's `try` patterns.

==== Error handling operators
The `onError` at the end of the chain is akin to a `try/catch` block. There,
execution skips to the catch in case an Exception is thrown:
[source,java]
----
Flux<String> s = Flux.range(1, 10)
    .map(v -> doSomethingDangerous(v)) <1>
    .map(v -> doSecondTransform(v)); <2>
s.subscribe(value -> System.out.println("RECEIVED " + value), <3>
    error -> System.err.println("CAUGHT " + error) <4>
);
----
<1> a transformation is performed that can throw an exception.
<2> if everything went well, a second transformation is performed.
<3> each successfully transformed value is printed out.
<4> in case of an error, the sequence terminates and an error message is displayed.

This is conceptually similar to the following try/catch block:
[source,java]
----
try {
  for (int i = 1; i < 11; i++) {
    String v1 = doSomethingDangerous(i); <1>
    String v2 = doSecondTransform(v1); <2>
    System.out.println("RECEIVED " + v2);
  }
} catch (Throwable t) {
  System.err.println("CAUGHT " + t); <3>
}
----
<1> if an exception is thrown here...
<2> ...the rest of the loops is skipped...
<3> ...and the execution goes straight to here.

Now that we've established a parallel, you may be familiar with several ways of
dealing with exceptions in a try/catch block. Most notably:

 1. catch and return a default value
 2. catch and execute an alternative path (fallback method)
 3. catch, wrap to a `BusinessException` and re-throw
 4. catch, log an error specific message and re-throw
 5. the `finally` block to clean up resources, or a Java 7's "try-with-resource" construct

All of these have equivalent in Reactor, in the form of error handling operators.

The equivalent of **(1)** is `onErrorReturn`:
[source,java]
----
Flux.just(10)
    .map(this::doSomethingDangerous)
    .onErrorReturn("DEFAULT_VALUE");
----

You also have the option of dynamically choosing the single value depending on
the exception that occurred:
[source,java]
----
Flux.just(10)
    .map(this::doSomethingDangerous)
    .onErrorReturn(e -> valueForError(e));
----

If you want more than a single default value and you have an alternative safer
way of processing your data, you can use `switchOnError`. This would be the
equivalent of *(2)*.

For example, if your nominal process is fetching data from an external
unreliable service, but you also keep a local cache of the same data that _can_
be a bit more out of date but is more reliable, you could do the following:
[source,java]
----
Flux.just("key1", "key2")
    .flatMap(k ->
        callExternalService(k) <1>
          .switchOnError(getFromCache(k)) <2>
    );
----
<1> for each key, we asynchronously call the external service.
<2> if the external service call fails, we fallback to the cache for that key.

Unlike `onErrorReturn`, `switchOnError` always falls back to the same sequence.
However it has variants that let you filter which exceptions to fallback on,
based either on the exception's class or a `Predicate`.

For more dynamic options, `onErrorResumeWith` is the more advanced alternative.
It takes a `Function` that maps the error to the fallback sequence to switch to:
[source,java]
----
Flux.just("key1", "key2")
    .flatMap(k ->
        callExternalService(k)
          .onErrorResumeWith(error -> { <1>
            if (error instanceof TimeoutException) <2>
              return getFromCache(k);
            else if (error instanceof UnknownKeyException)  <3>
              return registerNewEntry(k, "DEFAULT");
            else
              return Flux.error(error); <4>
          })
    );
----
<1> The function allows to dynamically choose how to continue.
<2> If the source times out, let's hit the local cache.
<3> If the source says the key is unknown, let's create a new entry.
<4> In all other cases, "re-throw".

That last line inside the `flatMap` gives us an hint as to how item *(3)* (catch
wrap and rethrow) could be achieved:
[source,java]
----
Flux.just("key1")
    .flatMap(k -> callExternalService(k)
        .onErrorResumeWith(original -> Flux.error(
            new BusinessException("oops", original))
        )
    );
----

For cases where you want the error to continue propagating, but you still want
to react to it without modifying the sequence (for instance logging it like in
item *(4)*), there is the `doOnError` operator. This operator as well as all
`doOn` prefixed operators are sometimes referred to as a "side-effect". That is
because they allow to peek inside the sequence's events without modifying them.

The example below makes use of that to ensure that when we fallback to the cache,
we at least log that the external service had a failure. We could also imagine
we have statistic counters to increment as an error side-effect...
[source,java]
----
Flux.just("key1")
    .flatMap(k -> callExternalService(k) <1>
        .doOnError(e -> log("uh oh, falling back, service failed for key " + k)) <2>
        .switchOnError(getFromCache(k)) <3>
    );
----
<1> the external service call that can fail...
<2> is decorated with a logging side-effect...
<3> and then protected with the cache fallback.

The last parallel to draw with the imperative world is the cleaning up that can
be done either via a Java 7 "try-with-resources" construct or the use of the
`finally` block (*(5)*). Both have their Reactor equivalent, actually: `using`
and `doFinally`:
[source,java]
----
Flux.using(
    () -> getDisposableResource(), <1>
    disposable -> Flux.just(disposable.toString()), <2>
    Disposable::dipose <2>
);
----
<1> The first lambda generates the resource. Let's assume this returns a `Disposable`.
<2> The second lambda processes the resource, returning a `Flux<T>`.
<3> The third lambda is called when the flux from 2) terminates or is cancelled, to clean up resources.

On the other hand, `doFinally` is about side-effects that you want to be executed
whenever the sequence terminates, either with onComplete, onError or a cancel.
It gives you a hint as to what kind of termination triggered the side-effect:
[source,java]
----
Flux.just("foo")
    .doFinally(type -> {
      if (type == SignalType.CANCEL) <1>
        Statistics.incrementCancelCount(); <2>
    });
----
<1> `doFinally` consumes a `SignalType` for the type of termination.
<2> here we increment statistics in case of cancellation only.

In order to demonstrate that all these operators don't prevent the upstream
original sequence to terminate when the error happens, let's take a more visual
example with a `Flux.interval`. The interval operator ticks every x units of time
with an increasing `Long`:
[source,java]
----
Flux.intervalMillis(250)
    .map(input -> {
        if (input < 3) return "tick " + input;
        throw new RuntimeException("boom");
    })
    .onErrorReturn("Uh oh")
    .subscribe(System.out::println);

Thread.sleep(2100); <1>
----
<1> Note that `intervalMillis` executes on the *timer* `Scheduler` by default.
Assuming we'd want to run that example in a main class, we add a sleep here so
that the application doesn't exit immediately without any value being produced.

This prints out, one line every 250ms:
----
tick 0
tick 1
tick 2
Uh oh
----

Even with one extra second of runtime, no more tick comes in from the `interval`.
The sequence was indeed terminated by the error.

There is another operator of interest with regards to error handling, and you
might be tempted to use it in the case above. `retry`, as its mame indicates,
allows to retry an erroring sequence.

But the caveat is that it works by *re-subscribing* to the upstream `Flux`. So
this is still in effect a different sequence, and the original one is still
terminated. To verify that, we can re-use the previous example and append a
`retry(1)` to retry once instead of the onErrorReturn:
[source,java]
----
Flux.intervalMillis(250)
    .map(input -> {
        if (input < 3) return "tick " + input;
        throw new RuntimeException("boom");
    })
    .elapsed() <1>
    .retry(1)
    .subscribe(System.out::println,
      System.err::println); <2>

Thread.sleep(2100); <3>
----
<1> `elapsed` will associate each value with the duration since previous value
was emitted.
<2> We also want to see when there is an `onError`
<3> We have enough time for our 4x2 ticks

This prints out:
----
259,tick 0
249,tick 1
251,tick 2
506,tick 0 <1>
248,tick 1
253,tick 2
java.lang.RuntimeException: boom
----
<1> Here a new `interval` started, from tick 0. The additional 250ms duration is
coming from the 4th tick, the one that causes the exception and subsequent retry

As you can see above, `retry(1)` merely re-subscribed to the original `interval`
once, restarting the tick from 0. The second time around, since the exception
still occurs, it gives up and propagate it downstream.

==== How are exceptions in operators or functions handled?
In general, all operators can themselves contain code that potentially trigger
an exception, or calls a user-defined callback that similarly can fail, so they
all contain some form of error handling.

As a rule of thumb, an **Unchecked Exception** will always be propagated through
`onError`. For instance, throwing a `RuntimeException` inside a `map` function
will translate to an `onError` event:

[source,java]
----
Flux.just("foo")
    .map(s -> { throw new IllegalArgumentException(s); })
    .subscribe(v -> System.out.println("GOT VALUE"),
               e -> System.out.println("ERROR: " + e));
----

This would print out:
----
ERROR: java.lang.IllegalArgumentException: foo
----

Reactor however defines a set of exceptions that are always
deemed **fatal**footnote:[think `OutOfMemoryError`. Have a look at the `Exceptions.throwIfFatal` method for details]
, meaning that Reactor cannot keep operating. These are thrown rather than
propagated.

NOTE: *Internally* There are also cases where an unchecked exception still
cannot be propagated, most notably during the subscribe and request phases, due
to concurrency races that could lead to double onError/onComplete. When these
races happen, the error that cannot be propagated is "dropped". These cases can
still be managed to some extent, as the error goes through the
`Hooks.onErrorDropped` customizable hook.

You may wonder, what about **Checked Exceptions**?

If, say, you need to call some method that declares it `throws` exceptions, you
will still have to deal with said exceptions in a `try/catch` block. You have
several options, though:

 1. catch the exception and recover from it, the sequence continues normally.
 2. catch the exception and wrap it into an _unchecked_ one, then throw it
    (interrupting the sequence). The `Exceptions` utility class can help you
    with that (see below).
 3. if you're expected to return a `Flux` (eg. you're in a `flatMap`), just wrap
    the exception into an erroring flux: `return Flux.error(checkedException)`.
    (the sequence also terminates)

Reactor has an `Exceptions` utility class that you can use, notably to ensure
that exceptions are wrapped only if they are checked exceptions:

 - use the `Exceptions.propagate` method to wrap exceptions if necessary. It will also call
   `throwIfFatal` first, and won't wrap `RuntimeException`.
 - use the `Exceptions.unwrap` method to get the original unwrapped exception (going back to
   the root cause of a hierarchy of reactor-specific exceptions).

Let's take the example of a `map` that uses a conversion method that can throw
an `IOException`:
[source,java]
----
public String convert(int i) throws IOException {
	if (i > 3) {
		throw new IOException("boom " + i);
	}
	return "OK " + i;
}
----

Now imagine you want to use that method in a `map`. You now have to explicitly
catch the exception, and your map function cannot re-throw it. So you can
propagate it to map's `onError` as a `RuntimeException`:
[source,java]
----
Flux<String> converted = Flux
    .range(1, 10)
    .map(i -> {
      try { return convert(i); }
      catch (IOException e) { throw Exceptions.propagate(e); }
    });
----

Later on, when subscribing to the above flux and reacting to errors, eg. in the
UI, you could revert back to the original exception in case you want to do
something special for IOExceptions:
[source,java]
----
converted.subscribe(
    v -> System.out.println("RECEIVED: " + v),
    e -> {
      if (Exceptions.unwrap(e) instanceof IOException) {
        System.out.println("Something bad happened with I/O");
      } else {
        System.out.println("Something bad happened");
      }
    }
);
----

=== Processor
==== Do I need a Processor?
