Processors are a special kind of `Publisher` that are also a `Subscriber`.
They were originally intended as a possible representation of an intermediate step that
could then be shared between Reactive Streams implementations. In Reactor however, such
steps are rather represented by operators that are `Publisher`.

A common mistake when coming across a `Processor` for the first time is the temptation to
directly call the exposed `onNext`, `onComplete` and `onError` methods from the `Subscriber` interface.

Such manual calls should be made with care, especially regarding external synchronization of calls
with respect to the Reactive Streams specification.
Processors are actually probably marginally useful, unless one comes across a Reactive Streams
based API that requires a `Subscriber` to be passed, rather than exposing a `Publisher`.

Sinks are usually a better alternative.
In Reactor a sink is a class that allows safe manual triggering of signals. It can either
be associated to a subscription (from inside an operator) or completely standalone.

Since `3.4.0`, an effort has been started to hide concrete processor implementations and
advertise the standalone sink pattern first and foremost:

 - concrete processor implementations are deprecated and slated for removal in 3.5.0
 - processors can still be constructed through the `Processors` utility class, which bears
 factory methods for the base case of each `Processor`, as well as access to `.more()` factory
 methods.
 - standalone sinks are constructed through factory methods in the `Sinks` class.

In the next section, we'll provide guidelines on how to choose whether or not to use a
`Processor` or a sink.

= Do I Need a `Processor` / a sink?

Most of the time, you should try to avoid using a `Processor`. They are harder to use
correctly and prone to some corner cases.

If you think a `Processor` could be a good match for your use case, always try these
three alternatives first (in order of preference):

. Could an operator or combination of operators fit the bill? (See <<which-operator>>.)
. Could a <<producing,"`generator`">> operator work instead? (Generally, these operators
are made to bridge APIs that are not reactive, providing a sink per `Subscriber` for that
purpose).
. Could a <<sinks,"standalone sink">> from `Sinks` work?

If, after exploring the above alternatives, you still think you need a `Processor`, read
the <<processor-overview>> section to learn about the different implementations.

[[sinks]]
= Safely Produce from Multiple Threads by Using `StandaloneFluxSink` and `StandaloneMonoSink`

Rather than directly using Reactor `Processors`, it is a good practice to use `Sinks` to
manually produce signals, with thread safety.

Most `Processors` flavors have an equivalent in `Sinks`. For example, `Processors.replayAll()`:

====
[source,java]
----
StandaloneFluxSink<Integer> replaySink = Sinks.replayAll();
----
====

Multiple producer threads may concurrently generate data on the sink by doing the following:

====
[source,java]
----
sink.next(1).next(2).next(3);
----
====

Parallel to that, the sink can be presented to downstream consumers as a `Publisher` (a `Flux`
or a `Mono`), like in the below example:

====
[source,java]
----
Flux<Integer> fluxView = replaySink.asFlux();
fluxView
	.takeWhile(i -> i < 10)
	.log()
	.blockLast();
----
====


The `Sinks` flavors that can be viewed as `Flux` are:

. `multicast()`: a sink that will transmit only newly pushed data to its subscribers, honoring their backpressure (newly pushed as in "after the subscriber's subscription").
. `multicastPreWarming()`: same as above, with the twist that data pushed before the first subscriber registers is buffered.
. `multicastReplayAll()`: a sink that will replay all the history of pushed data to new subscribers then continue pushing new data live.
. `multicastReplay(int)`: same as above, except the history of replayed data is limited in size.
. `unicast()`: the only sink that won't accept more than one `Subscriber`, but honors their backpressure
(and replays elements pushed to it before the Subscriber arrives)

There is currently only one `Sinks` flavor that can be viewed as `Mono`:

. `trigger()`: a sink that will wait for a `Mono`-like interaction, propagate it to current `Subscribers` and additionally cache it for replaying to any late `Subscriber`.

[[processor-overview]]
= Overview of Available Processors

== Direct Processor

A direct `Processor` is a very simple processor that can dispatch signals to zero or more
`Subscribers`. On the other hand, *it has the limitation of not handling backpressure*.
As a consequence, a `DirectProcessor` signals an `IllegalStateException` to its
subscribers if you push N elements through it but at least one of its subscribers has
requested less than N.

This aspect makes it a bit niche, and so the (only) factory method to create a direct processor
is hidden a bit: it is created via `Processors.more().multicastNoBackpressure()`.

Once the `Processor` has terminated (usually through its sink's `error(Throwable)` or
`complete()` methods being called), it lets more subscribers subscribe but replays the
termination signal to them immediately.

== Unicast Processor

A unicast `Processor` can deal with backpressure by using an internal buffer. The trade-off
is that it can have _at most one_ `Subscriber`.

The basic unicast processor is created via `Processors.unicast()`.
But since it has a few more options than a direct processor, there are a few additional
`unicast` static factory methods in `Processors#more()`.

For instance, by default, it is unbounded: If you push any amount of data through it while
its `Subscriber` has not yet requested data, it buffers all of the data.
You can change this by providing a custom `Queue` implementation for the internal
buffering in the `Processors.more().unicast(Queue)` factory method.
If that queue is bounded, the processor could reject the push of a value when the buffer
is full and not enough requests from downstream have been received.

In that _bounded_ case, you can also build the processor with a callback that is invoked
on each rejected element, allowing for cleanup of these rejected elements.

== Multicast Processor

An multicast `Processor` (sometimes referred to as an "emitter" processor) can emit to several
subscribers while honoring backpressure for each of its subscribers.
Subscribers receive only the signals pushed through the processor after they have subscribed.

The basic multicast processor is created via `Processors.multicast()`.

By default, if all of its subscribers are cancelled (which basically means they have all
un-subscribed), it clears its internal buffer and stops accepting new subscribers.
You can tune this by using the `autoCancel` parameter in the `multicast` static factory methods
under `Processor.more()`.

== Replay Processor

A replay `Processor` caches elements from its upstream `Publisher` and replays them to late subscribers.

It can be created in multiple configurations:

* Caching a limited history (`Processors.replay(int)`) or an unbounded history (`Processors.replayAll()`).
* Caching a time-based replay window (`Processors.replayTimeout(Duration)`).
* Caching a combination of history size and time window (`Processors.replaySizeOrTimeout(int, Duration)`).

Additional overloads for fine tuning of the above can also be found under `Processors.more()`, as well
as a variant that allows caching of a single element (`replayLatest()` and `replayLatestOrDefault(T)`).


//TODO == MonoProcessor
