Processors are a special kind of `Publisher` that are also a `Subscriber`. That means
that you can `subscribe` to a `Processor` (generally, they implement `Flux`), but you can
also call methods to manually inject data into the sequence or terminate it.

There are several kinds of Processors, each with a few particular semantics, but before
you start looking into these, you need to ask yourself the following question:

= Do I Need a Processor?

Most of the time, you should try to avoid using a `Processor`. They are harder to use
correctly and prone to some corner cases.

If you think a `Processor` could be a good match for your use case, ask yourself if you
have tried these two alternatives:

. Could an operator or combination of operators fit the bill? (See <<which-operator>>.)
. Could a <<producing,"`generator`">> operator work instead? (Generally, these operators
are made to bridge APIs that are not reactive, providing a "`sink`" that is similar in
concept to a `Processor`, in the sense that it lets you manually populate the sequence
with data or terminate it).

If, after exploring the above alternatives, you still think you need a `Processor`, read
the <<processor-overview>> section to learn about the different implementations.

= Safely Produce from Multiple Threads by Using the `Sink` Facade

Rather than directly using Reactor `Processors`, it is a good practice to obtain a `Sink`
for the `Processor` by calling `sink()` *once*.

`FluxProcessor` sinks safely gate multi-threaded producers and can be used by
applications that generate data from multiple threads concurrently. For example, you can create a
thread-safe serialized sink for `UnicastProcessor` by doing the following:

====
[source,java]
----
UnicastProcessor<Integer> processor = UnicastProcessor.create();
FluxSink<Integer> sink = processor.sink(overflowStrategy);
----
====

Multiple producer threads may concurrently generate data on the following serialized
sink by doing the following:

====
[source,java]
----
sink.next(n);
----
====

WARNING: Despite the `FluxSink` being adapted for multi-threaded *manual* feeding
of the `Processor`, it is not possible to mix the subscriber approach with the
sink approach: You have to either subscribe your `FluxProcessor` to a source
`Publisher` or feed it manually though its `FluxSink`.

Overflow from `next` behaves in two possible ways, depending on the `Processor` and its
configuration:

* An unbounded processor handles the overflow itself by dropping or buffering.
* A bounded processor blocks or "`spins`" on the `IGNORE` strategy or applies the
`overflowStrategy` behavior specified for the `sink`.

[[processor-overview]]
= Overview of Available Processors

Reactor Core comes with several flavors of `Processor`. Not all processors have the same
semantics, but they are roughly split into three categories. The following list briefly
describes the three kinds of processors:

* *direct* (`DirectProcessor` and `UnicastProcessor`): These processors can push
data only through direct user action (calling their methods of their `Sink` directly).
* *synchronous* (`EmitterProcessor` and `ReplayProcessor`): These processors can either push data
through user interaction or by subscribing to an upstream `Publisher` and synchronously
draining it.

TIP: One way of publishing events onto different threads is to use the `EmitterProcessor`
combined with `publishOn(Scheduler)`. This can for example replace the former `TopicProcessor`,
which was using `Unsafe` operations and has been moved to
https://github.com/reactor/reactor-addons/tree/master/reactor-extra/src/main/java/reactor/extra/processor[reactor-extra]
in 3.3.0.

== Direct Processor

A direct `Processor` is a processor that can dispatch signals to zero or more
`Subscribers`. It is the simplest one to instantiate, with a single `DirectProcessor#create()` static
factory method. On the other hand, *it has the limitation of not handling backpressure*.
As a consequence, a `DirectProcessor` signals an `IllegalStateException` to its
subscribers if you push N elements through it but at least one of its subscribers has
requested less than N.

Once the `Processor` has terminated (usually through its sink's `error(Throwable)` or
`complete()` methods being called), it lets more subscribers subscribe but replays the
termination signal to them immediately.

== Unicast Processor

A unicast `Processor` can deal with backpressure by using an internal buffer. The trade-off
is that it can have _at most one_ `Subscriber`.

A `UnicastProcessor` has a few more options than a direct processor, reflected by the existence of a few `create` static factory
methods. For instance, by default, it is unbounded: If you push any amount of
data through it while its `Subscriber` has not yet requested data, it buffers all of
the data.

You can change this by providing a custom `Queue` implementation for the internal
buffering in the `create` factory method. If that queue is bounded, the processor could
reject the push of a value when the buffer is full and not enough requests from
downstream have been received.

In that _bounded_ case, you can also build the processor with a callback that is invoked
on each rejected element, allowing for cleanup of these rejected elements.

== Emitter Processor

An emitter `Processor` can emit to several subscribers while honoring
backpressure for each of its subscribers. It can also subscribe to a `Publisher` and
relay its signals synchronously.

Initially, when it has no subscriber, it can still accept a few data pushes up to a
configurable `bufferSize`. After that point, if no `Subscriber` has come in and consumed
the data, calls to `onNext` block until the processor is drained (which can happen only
concurrently by then).

Thus, the first `Subscriber` to subscribe receives up to `bufferSize` elements upon
subscribing. However, after that, the processor stops replaying signals to additional
subscribers. These subsequent subscribers instead receive only the signals pushed through
the processor after they have subscribed. The internal buffer is still used for
backpressure purposes.

By default, if all of its subscribers are cancelled (which basically means they have all
un-subscribed), it clears its internal buffer and stops accepting new subscribers.
You can tune this by using the `autoCancel` parameter in the `create` static factory methods.

== Replay Processor

A replay `Processor` caches elements that are either pushed directly through its `sink()`
or elements from an upstream `Publisher` and replays them to late subscribers.

It can be created in multiple configurations:

* Caching a single element (`cacheLast`).
* Caching a limited history (`create(int)`) or an unbounded history (`create()`).
* Caching a time-based replay window (`createTimeout(Duration)`).
* Caching a combination of history size and time window
(`createSizeOrTimeout(int, Duration)`).

//TODO == MonoProcessor
